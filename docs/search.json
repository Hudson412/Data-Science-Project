[
  {
    "objectID": "valentines_day.html",
    "href": "valentines_day.html",
    "title": "Valentines Day",
    "section": "",
    "text": "The data set used in this project, Valentine’s Day Consumer Data, is sourced from TidyTuesday. TidyTuesday is a weekly R project that encourages users to create visualizations using that week’s data set for wrangling and visualizing the data.\nThis particular data set is from the February 13, 2024 edition of TidyTuesday. Using information from surveys conducted by the National Retail Federation in the United States, we have information on how individual’s celebrate Valentine’s Day annually. The data in this project is form 2010 to 2022, thanks to Suraj Das’s work on Kaggle.\nIn analyzing the data set, I decided to look for a relationship between the average amount spent on Valentine’s Day gifts and the percent of individuals celebrating the holiday.\n\n\n\n\n\n\n\n\n\nAnalyzing this chart, we observe a relatively negative correlation between the two variables. A possible trend that one could suggest through this visualization is that during years when there is a smaller proportion of individuals celebrating the holiday in a given year, those who do decide to celebrate are much more passionate about their gifts. This may give reason to why the average amount spent per person is marginally higher during years where the percent celebrating Valentine’s Day is lower in comparison to other years.\nConversely and more realistically, one could interpret the visualization in saying that as more people celebrate, total spending is spread across a broader population. A larger spread could possibly lower the average amount per person as the effect of an extreme outlier would not be as influential as it is in a year with less people celebrating. An average is a value that is greatly affected by outliers, but as the number of observations increases, the effect of the outlier weakens."
  },
  {
    "objectID": "Final_Presentation.html#overview-of-data",
    "href": "Final_Presentation.html#overview-of-data",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Overview of Data",
    "text": "Overview of Data\n\nAnalysis of Netflix Movies & TV Shows\n\nData from TidyTuesday (2021-04-20)\nFocus on trends in U.S. content, title length, and naming conventions\n\nData originally collected by Shivam Bansal on Kaggle"
  },
  {
    "objectID": "Final_Presentation.html#visualization-1---netflix-content-trends-over-time-in-the-united-states",
    "href": "Final_Presentation.html#visualization-1---netflix-content-trends-over-time-in-the-united-states",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Visualization 1 - Netflix Content Trends Over Time in the United States",
    "text": "Visualization 1 - Netflix Content Trends Over Time in the United States"
  },
  {
    "objectID": "Final_Presentation.html#visualization-1-analysis",
    "href": "Final_Presentation.html#visualization-1-analysis",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Visualization 1 Analysis",
    "text": "Visualization 1 Analysis\nFrom 2015 onward, there is a steep increase in content added to Netflix in the U.S. Movies drive most of the growth, but TV Shows also rise sharply.\n\nThe sudden drop in 2021 likely reflects:\n\nCOVID-19 production slowdowns\nPartial year data\nInternal Netflix policy shifts\n\n\nIncreased User Retention"
  },
  {
    "objectID": "Final_Presentation.html#visualization-2---average-netflix-title-length-over-time",
    "href": "Final_Presentation.html#visualization-2---average-netflix-title-length-over-time",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Visualization 2 - Average Netflix Title Length Over Time",
    "text": "Visualization 2 - Average Netflix Title Length Over Time"
  },
  {
    "objectID": "Final_Presentation.html#visualization-2-analysis",
    "href": "Final_Presentation.html#visualization-2-analysis",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Visualization 2 Analysis",
    "text": "Visualization 2 Analysis\n\nMovie title lengths have fluctuated over time, with consistently longer titles after 2015.\nTV show title lengths fluctuated from 2000-2012\n\nSince 2012, TV titles have stabilized between 15–17 characters\n\nMovie titles are now typically longer than TV Shows"
  },
  {
    "objectID": "Final_Presentation.html#visualization-3---netflix-titles-starting-with-a-or-an-over-time",
    "href": "Final_Presentation.html#visualization-3---netflix-titles-starting-with-a-or-an-over-time",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Visualization 3 - Netflix Titles Starting with ‘A’ or ‘An’ Over Time",
    "text": "Visualization 3 - Netflix Titles Starting with ‘A’ or ‘An’ Over Time"
  },
  {
    "objectID": "Final_Presentation.html#visualization-3-analysis",
    "href": "Final_Presentation.html#visualization-3-analysis",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Visualization 3 Analysis",
    "text": "Visualization 3 Analysis\n\nBetween 2008-2014 the proportion of titles beginning with ‘A’/‘An’ was extremely low. 2011 and 2013 are outlier years possibly explained by:\n\nLow total title counts\nCertain acquisitions that skewed overall\n\nThe proportion of titles beginning with these articles increased sharply from 2015 on\n\nThis growth may reflect a gaming of alphabetization in recommendation interfaces.\n\nThese proportions stabilize between 1.5-2.5% of all titles."
  },
  {
    "objectID": "Final_Presentation.html#summarized-conclusions",
    "href": "Final_Presentation.html#summarized-conclusions",
    "title": "Presentation of Netflix Title Analysis",
    "section": "Summarized Conclusions",
    "text": "Summarized Conclusions\n\nNetflix’s title trends reflect strategic business choices:\n\nRapid content expansion\nTitle naming decisions\n\nThese patterns provide insight into how data can shift business models in the streaming industry\nAs the overall number of titles released on Netflix grew, the proportion of titles with ‘A’/‘An’ increased as well."
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "Ethical Analysis of Amazon’s AI Reruiting Tool",
    "section": "",
    "text": "In 2014, Amazon developed a recruiting tool that used artificial intelligence to scan resumes in order to increase the efficiency of the hiring process for positions at the company. This tool was originally intended to automatically and quickly identify top candidates from a pool by learning patters from historical hiring data. Eventually, however, Amazon realized that the algorithm was actually quite unfair. It was consistently downgrading resumes that included the word “women” or came from an individual attending a women’s college. The tech giant ultimately traced the bias back to the original data that the model was based off of. The data came from the past 10 years of hiring data, which mainly consisted of male applicants. During this period, there was a national trend where the majority of positions in the tech industry were filled by men. The model taught itself that male candidates were preferable for the company, reflecting the male dominance in the field and Amazon’s historical applicant pool. Thus, the tool led to discriminating against female candidates, and the firm discontinued use of this artificial intelligence tool for recruitment. This occurrence as a whole presents a significant ethical dilemma. (Dastin 2018)\nOthers argue that Amazon was not completely at fault for this hiring flaw as bias in AI can be driven by a multitude of factors. There are many factors unrelated to the data that the tool pulls from that could have caused this issue. The individuals that use the tool along with other external variables can adjust how artificial intelligence “feels” towards something. (Lavanchy 2018)\nWhen companies collect data from job applicants, there is an expectation that the information will be used solely for evaluating their candidacy. Speaking to the permission structure for using the data in this situation, the resumes used to train Amazon’s hiring tool were originally submitted for the purpose of obtaining employment at the company. Job applicants were sharing their personal information, in the form of a resume, under the impression that only job recruiters were the only individuals using this information. There is no evidence that the applicants were explicitly informed that the data would actually be used to train an artificial intelligence system. And this goes for individuals from a period of ten years that applied to Amazon. Thus, it is unclear whether or not the permission structure of using the data was not correctly followed, as there is no evidence that applicants were informed their resumes would be used to train an AI system. Presumably, most candidates submitted their information with the expectation that they would be reviewed for the sole purpose of employment consideration. If the company had explicitly specified that resumes would be used for their typical usage and model training, then the permission structure would have been followed a bit closer. (Dastin 2018)\nFor an algorithm to make fair decisions, the data it is trained on must accurately represent the population it will be applied to. One of if not the largest flaws in this situation is who was measured to train the algorithm. As stated in the overview of the event, the hiring tool was trained on resumes sent in to Amazon over a ten year period. This information was primarily submitted for technical roles at the company. This period stands in the middle of the tech industry’s extreme gender imbalance (Lavanchy 2018). For many years, jobs within the tech world have been dominated by males. Thus, the applicant pool that Amazon pulled its resumes from was extremely skewed toward men. For this reason, the algorithm quickly began to associate male characteristics and applicants with successful candidates (those who were hired in the past). The usage of this model would only reaffirm and amplify existing biases in the field. Using this dataset to generalize or apply the algorithm to all applicants for the position at Amazon is unethical and results in biased outcomes. We must raise concerns when analyzing data that we do not know how it was collected. (Dastin 2018)\nIdentifiable data is information that can be directly traced back to a specific individual. A few examples would include things like names, contact information, and other unique identifiers. In order to protect the privacy of customers, companies will typically try to keep this information secure or anonymized by removing identifiers. In this situation, Amazon was working with resumes, which contain lots of personal identifiable information like names, education, and work experience. Thus, the information within this data was inherently identifiable. Neither article explicitly mentions whether any anonymization processes were used before the data was used for the algorithm. While there is no evidence of the data being leaked or misused externally, the lack of transparency on Amazon’s part is concerning. Since the algorithm learned every detail on the resumes, including identifying details, the risk of identification and unintended use of personal data remained unethically significant. (Dastin 2018)\n\nGender is a complex variable, especially in contexts like hiring where fairness and equal opportunity are critical. Even when gender is not meaningfully included as a data point, learned algorithms can infer an individuals gender. This inference can then lead to biased or discriminatory outcomes if it is not carefully managed. Amazon’s AI hiring tool penalized resumes that included the word “women’s” or gave reason for the algorithm to believe the applicant was female (Lavanchy 2018). This is an example of how gender can become a proxy variable in data science even when it is not explicitly included in a study. Thus, using race or gender as variables in artificial intelligence like hiring algorithms is unethical as it can serve as a proxy for continued social disadvantages. Furthermore, these disadvantages would ultimately lead to discrimination and worsened inequalities.\n\n\n\n\n\n\nReferences\n\nDastin, Jeffrey. 2018. “Insight - Amazon Scraps Secret AI Recruiting Tool That Showed Bias Against Women.” Reuters. https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G/.\n\n\nLavanchy, Maude. 2018. “Amazon’s Sexist Hiring Algorithm Could Still Be Better Than a Human.” IMD. https://www.imd.org/research-knowledge/digital/articles/amazons-sexist-hiring-algorithm-could-still-be-better-than-a-human/."
  },
  {
    "objectID": "simulation_study.html",
    "href": "simulation_study.html",
    "title": "Simulation Study",
    "section": "",
    "text": "The data set used in this project, Hollywood Age Gaps, is sourced from TidyTuesday. TidyTuesday is a weekly R project that encourages users to create visualizations using that week’s data set for wrangling and visualizing the data.\nThis particular data set is from the February 14, 2023 edition of TidyTuesday. Using information from Data is Plural, we have information on the age gap between movie love interests. The characters must not be animated, the youngest actor must be at least 17 years old, and the relationship must be an actual love interest.\nThe purpose of this analysis is to investigate whether there is a significant difference in the average age gap between romantic pairs in Hollywood films based on the type of relationship. We will look into two relationship types: The first is when the older actor is a man and the younger is a woman while the second is the opposite where the older actor is a woman and the younger actor is a man.\nNull Hypothesis: The average age gap between Male-Older and Female-Older relationships is the same.\nAlternative Hypothesis: The average age gap in Male-Older relationships is not the same as Female-Older relationships.\nFirst, a visualization of the original data and variables of interest are included for the reader to understand the extent of the difference of the relationship.\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(\"tidytuesdayR\")\nlibrary(\"ggplot2\")\n\nset.seed(47)\n\ntuesdata &lt;- tidytuesdayR::tt_load(2023, week = 7)\n\nage_gaps &lt;- tuesdata$age_gaps\n\nage_gaps &lt;- age_gaps |&gt;\n  mutate(relationship_type = ifelse(character_1_gender == \"man\" & character_2_gender == \"woman\", \"Male-Older\", \"Female-Older\"))\n\nobserved_diff &lt;- age_gaps |&gt;\n  group_by(relationship_type) |&gt;\n  summarize(mean_age_diff = mean(age_difference, na.rm = TRUE)) |&gt;\n  summarize(diff = diff(mean_age_diff)) |&gt;\n  pull(diff)\n\n\nrandom_age_diff &lt;- function(data) {\n  shuffled_data &lt;- data |&gt;\n    mutate(relationship_type = sample(relationship_type))\n  \n  mean_diffs &lt;- shuffled_data |&gt;\n    group_by(relationship_type) |&gt;\n    summarize(mean_age_diff = mean(age_difference, na.rm = TRUE)) |&gt;\n    summarize(diff = diff(mean_age_diff)) |&gt;\n    pull(diff)\n  \n  return(mean_diffs)\n}\n\nage_gaps |&gt;\n  ggplot(aes(x = relationship_type,\n             y = age_difference,\n  )) + \n  geom_boxplot() +\n  labs(\n    x = \"Relationship Type\",\n    y = \"Age Difference\",\n    title = \"Distribution of Age Differences by Relationship Type\") \n\n\n\n\n\n\n\n\n\nWe first observe a noticeably large gap in the age difference between the two relationship types. The median age difference of Male-older relationships is greater than the 75th percent quartile of the Female-older relationships. Additionally, the 25th percent quartile of Male-older relationships is higher than even the median of Female-Older relationships.\n\n\nShow the code\nnum_sims &lt;- 1000\nnull_diffs &lt;- map_dbl(1:num_sims, ~ random_age_diff(age_gaps))\n\ndata.frame(null_diffs) |&gt; \n  ggplot(aes(x = null_diffs)) + \n  geom_histogram() + \n  geom_vline(xintercept = observed_diff, color = \"red\") + \n  labs(\n    x = \"Difference in Mean Age Gap (Male-Older - Female-Older)\",\n    y = \"Number of Relationships\",\n    title = \"Sampling Distribution of Age Gap Differences when Null Hypothesis is True\",\n  ) \n\n\n\n\n\n\n\n\n\nShow the code\np_value &lt;- mean(abs(null_diffs) &gt;= abs(observed_diff))\n\n\nI used a permutation test to simulate the null hypothesis by randomly shuffling the relationship type labels. The difference in mean age gaps was calculated for each permutation to generate a null distribution. The observed difference was then compared to this distribution to determine statistical significance.\nThe permutation test shows that the observed difference in mean age gaps between Male-Older and Female-older relationships is approximately 5.9, which is far from the center of the null distribution shown above. The calculated p-value of 0 indicates we have sufficient evidence to reject the null hypothesis that there is no difference in mean age gaps between these relationship types.\nTherefore, we can conclude that the difference in age gaps is statistically significant. Thus, there is a meaningful disparity between these relationship types that is not due to chance."
  },
  {
    "objectID": "holiday_travel.html",
    "href": "holiday_travel.html",
    "title": "Holiday Travel",
    "section": "",
    "text": "The data set used in this project, Global Holidays and Travel, is sourced from TidyTuesday. TidyTuesday is a weekly R project that encourages users to create visualizations using that week’s data set for wrangling and visualizing the data.\nThis particular data set is from December 24, 2024. It was found through an article by Shengjie Lai (et al). The information presented is available thanks to funding from The Bill and Melinda Gates Foundation. The data was then curated by Jon Harmon. Sources for the data itself are cited below.\nIn analyzing the data set, I decided to look for a relationship between the time of year and the number passengers while separating individuals dependent on whether the flight was domestic or international.\n\n\n\n\n\n\n\n\n\nTaking a look at the chart, we can observe that travel seems to have a cyclical nature. During the summer months of the year, June - September, flights seem to pick up and more individuals are traveling. This shift seems realistic as individuals typically travel during the warmer months of the year and when their children are on summer break. Domestic flights also seem to pick up towards the end of the year (holiday season).\nAdditionally, domestic flights consistently have higher passenger volumes compared to international flights across all 12 months of the year. Normally, international flights stay below 30,000 passengers per month. With this idea, domestic travel shows much more variability in passenger numbers compared to international travel.\nCitations:\nLai S., Sorichetta A. and WorldPop (2020). Global Public and School Holidays 2010-2019. Mapping seasonal denominator dynamics in low- and middle-income settings, and Exploring the seasonality of COVID-19, funded by The Bill and Melinda Gates Foundation.\nLai S., Sorichetta A. and WorldPop (2020). Monthly volume of airline passengers in 90 countries 2010-2018. Mapping seasonal denominator dynamics in low- and middle-income settings, and Exploring the seasonality of COVID-19, funded by The Bill and Melinda Gates Foundation."
  },
  {
    "objectID": "string_analysis.html",
    "href": "string_analysis.html",
    "title": "Netflix Titles",
    "section": "",
    "text": "The data set used in this project, Netflix Movies and TV Shows, is sourced from TidyTuesday. TidyTuesday is a weekly R project that encourages users to create visualizations using that week’s data set for wrangling and visualizing the data.\nThis particular data set is from the April 20, 2021 edition of TidyTuesday. Using information conducted by Flixable, a third party Netflix search engine, we have data detailing the amount of titles that Netflix offers. The data in this project comes thanks to Shivam Bansal’s work on Kaggle.\nIn analyzing the data set, I first decided to look at Netflix’s title releasing activity within the United States. The chart is separated by content type, either Movie or TV Show. Secondly, I aimed to look at how the length of titles has changed over time. Finally, I looked at the frequency of titles starting with the articles “A” or “An” has changed over the past decade.\n\n\n\n\n\n\n\n\n\nLooking at the produced chart, we observe an enourmous spike in title additions to Netflix. Starting around 2015, the company began to rapidly add more titles to their page. The pattern is evident in both Movies and TV Shows but more dramatic in Movies. Near the end of the graph we observe an extreme drop off that is likely due to the dataset being put together in the middle of the 2021. Otherwise, this shift could be a result of COVID-19 or other policy changes in titles.\nAnother key piece of information to keep in mind is that this chart specifically has to do with the United States, so international trends may differ. Much of Netflix’s audience is based in the United States, but they do have many users overseas. Many titles are available in only certain locations as well.\n\n\n\n\n\n\n\n\n\nThis chart is based off of all Netflix titles across the world, rather than just the United States. There doesn’t seem to be too much of an overall trend in either Movies or TV Shows. Movie titles showed significant volatility throughout the past decade with a noticeable uptick in 2016 that lasted until the boundary of this chart.\nTV Shows fluctuated even more extremely than Movies during the early portion of the chart. The value begins to level out/stabilize around 2012. This stabilization occurs at around 15-17 characters.\n\n\nShow the code\nnetflix |&gt;\n  mutate(added_year = str_extract(date_added, \"\\\\d{4}\")) |&gt;\n  filter(str_detect(added_year, \"\\\\d{4}\")) |&gt;\n  group_by(added_year) |&gt;\n  summarize(\n    total_titles = n(),\n    titles_with_article = sum(str_detect(title, \"^A\\\\b|^An\\\\b\")),\n    proportion = titles_with_article / total_titles,\n    .groups = \"drop\"\n  ) |&gt;\n  ggplot(aes(x = added_year, y = proportion)) +\n  geom_point() +\n  labs(\n    title = \"Proportion of Netflix Titles Starting with 'A' or 'An' Over Time\",\n    x = \"Year Added to Netflix\",\n    y = \"Proportion of Titles\"\n  )\n\n\n\n\n\n\n\n\n\nBetween the years 2008-2014, the proportion of titles added to Netflix that had titles starting with these articles was basically negligible and nonexistent. 2011 and 2013 are dramatic outliers from this pattern and the overall trend of the graph as a whole. It is likely a random coincidence but could be explained by producers aiming to land themselves a spot at the beginning of a list of titles sorted alphabetically. This is purely a speculation, but streaming platforms have now removed articles when sorting titles alphabetically.\nAround 2015, a notable uptick occurs as proportions begin to grow substantially above previous years. These proportions seem to stabilize between 1.5-2.5% of all titles. There is reason to believe that as the overall number of titles released on Netflix grew, the proportion of titles with ‘A’/‘An’ increased as well."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hudson’s Website",
    "section": "",
    "text": "Hi! I am a sophomore at Pomona College studying Math and Economics with a Minor in Data Science. Growing up in Pittsburgh, PA, I found the transition to living in California difficult at first but now love it. Professionally, I am currently pursuing a career in Investment Banking or Private Equity. Outside of professional and academic interests, I am currently training for an Ironman, love golfing, and enjoy playing poker in my free time.\nHere are a few links with more information about myself and the code for this website."
  },
  {
    "objectID": "traffic.html",
    "href": "traffic.html",
    "title": "Project 5",
    "section": "",
    "text": "In this analysis, I plan to look at traffic stops in three cities within the United States: Nashville, Raleigh, and San Diego. Each of these diverse locations should offer reasonably different outcome results. The three types of outcomes I looked at are warnings, citations, and arrests. Before performing on the data, I expect some simalarities between the Raleigh and Nashville data because they are situated geographically closer together than San Diego is with the cities. Using information from Stanford (Project 2020), I plan to control for the gender of individuals and see if males or females are stopped more frequently and how that varies among the three cities. Additionally I plan to look at potential trends in the outcomes of these traffic stops to see how gender and location may affect the traffic stop outcome.\n\n\n\n\n\n\n\n\n\nIn Nashville, warnings significantly dominate the arrest and citation outcomes for both genders. The overall trend of arrests being quite rare, followed by a much larger number of citations and a much, much larger number of warnings is visible in males and females. In males though, this pattern is exacerbated as the number of each outcome is respectively larger.\n\n\n\n\n\n\n\n\n\nIn San Diego, we observe an alternative trend where citations are actually the most common outcome regardless of gender. In both males and females, we see an extremely small number of arrests followed by a large number of warnings and even more citations.Again, this trend is even more noticeable in males compared to women. Females tend to receive more warnings relative to their total citation amount when compared to males.\n\n\n\n\n\n\n\n\n\nIn Raleigh, we observe a trend quite similar to San Diego. In both females and males, the number of arrests is significantly less than that of the larger number of warning outcomes and even larger citations. Arrests are quite rare in both groups but notably more frequent in males. Males again lead females in the volume of each outcome. Thus, males are stopped and penalized more frequently than females are.\nLooking at this analysis as a whole, I used SQL to adjust a group of datasets into a fine-tuned piece of data aligning with the goals of this project. I was then able to analyze such through visualization in R. Each visualization was faceted by gender and broke each traffic stop into either an arrest, citation, or warning.\nThe results suggest that gender does in fact influence traffic stop outcomes quite consistently across cities, specifically Nashville, San Diego, and Raleigh. Going further, males were always more heavily policed than females, being stopped and penalized in many more situations than females within each city.\n\n\n\n\n\n\nReferences\n\nProject, Stanford Open Policing. 2020. “Stanford Open Policing Project Dataset.”"
  }
]